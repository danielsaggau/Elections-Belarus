---
title: "lda"
author: "Daniel Saggau"
date: "3/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preprocessing the data into a text corpus (#TOD0)

Here we need to merge all the columns and create a giant text corpus. 

```{r}
library(tidyverse)

data = unite(lits3_gis,col = "text", country:b2c, sep =" ")

data = data %>%
  select("text")
view(text)
```


```{r}
library(lda)
library(topicmodels)
library(tidytext)
library(tm)
cleaner <- function(text){
  text <- tolower(text)
  text <- gsub("rt", "", text)
  text <- gsub("@\\w+", "", text)
  text <- gsub("[[:punct:]]", "", text)
  text <- gsub("http\\w+", "", text)
  text <- gsub("amp", " ", text)
  text <- gsub("[ |\t]{2,}", "", text)
  text <- gsub("^ ", "", text)
  text <- gsub(" $", "", text)
  text <- gsub(" +", " ", text)
  text <- gsub("=", " ", text)
  text <- gsub('<.*>', '', enc2native(text))
  text <- unique(text)
  return(text)
}

polish <- function(text){
  text <- VCorpus(VectorSource(text))
  text <- tm_map(text, removeWords, stopwords("english"))
  text <- tm_map(text, removeNumbers)
  text <- tm_map(text, stemDocument)
}

text = data$text 
text <- cleaner(text)
corpus <- polish(text)
```


# LDA (#TOD0)

```{r}

doc.lengths <- rowSums(as.matrix(DocumentTermMatrix(corpus)))
dtm <- DocumentTermMatrix(corpus[doc.lengths > 0])

#####################################################################################

LDA <- LDA(dtm, k =5,method = "VEM", cotrol = list(seed=1234))
topics <- tidy(LDA, matrix ="beta")

ap_top_terms <- topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
```









